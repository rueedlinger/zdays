{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to build a Naive Bayes classifier with the Python NLTK module. http://www.nltk.org/ \n",
    "\n",
    "In this example we build a language classifier with the top 1000 German and English words. With NLTK there is an easy way to build a classifier with your own features. The features are build as Python dictionaries.\n",
    "\n",
    "To classify German or English language we use the following features:\n",
    "\n",
    "|feature|description|\n",
    "|---|---|\n",
    "|word(foo)|True if the word 'foo' is found in the text|\n",
    "|sufix1| the last letter of the word.|\n",
    "|bigram(h,e)|True if word conatins the bigram 'he' |\n",
    "|trigram(t,h,e)| True if the word contains the trigram 'the'|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def get_features(word):\n",
    "    word = word.lower()\n",
    "    \n",
    "    feature = {'word('+ word + ')': True}\n",
    "    feature['sufix1'] =  word[-1:]\n",
    "    \n",
    "    \n",
    "    for ngram in  ngrams(word, 2):\n",
    "        feature['bigram' + str(ngram) + ''] = True\n",
    "    \n",
    "        \n",
    "    for ngram in  ngrams(word, 3):\n",
    "        feature['trigram' + str(ngram) + ''] = True\n",
    "    \n",
    "    \n",
    "    return feature\n",
    "        \n",
    "def get_features_from_file(file):\n",
    "\n",
    "    lines = [line.rstrip() for line in open(file)]\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for word in lines:\n",
    "        \n",
    "        features.append(get_features(word))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_features_from_sentenece(sentence):\n",
    "    features = {}\n",
    "    for word in sentence.split(' '):\n",
    "        features.update(get_features(word))\n",
    "    return features\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following command we build our feautres with the top 1000 German and English words,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresets_de = [(f, 'de') for f in get_features_from_file('data/top1000de.txt')]\n",
    "featuresets_en = [(f, 'en') for f in get_features_from_file('data/top1000en.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the words, because the most used words are at the beginning of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('German features', 1000)\n",
      "('English features', 1000)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(featuresets_de)\n",
    "random.shuffle(featuresets_en)\n",
    "\n",
    "print('German features', len(featuresets_de))\n",
    "print('English features', len(featuresets_de))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a German feautre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({\"bigram('b', 'e')\": True, \"bigram('g', 'a')\": True, \"bigram('a', 'u')\": True, \"bigram('a', 'b')\": True, \"trigram('f', 'g', 'a')\": True, 'sufix1': 'e', \"bigram('f', 'g')\": True, \"trigram('g', 'a', 'b')\": True, \"trigram('u', 'f', 'g')\": True, 'word(aufgabe)': True, \"bigram('u', 'f')\": True, \"trigram('a', 'u', 'f')\": True, \"trigram('a', 'b', 'e')\": True}, 'de')\n"
     ]
    }
   ],
   "source": [
    "print(featuresets_de[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of an English feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({\"trigram('w', 'h', 'a')\": True, 'sufix1': 't', \"bigram('w', 'h')\": True, \"trigram('h', 'a', 't')\": True, 'word(what)': True, \"bigram('a', 't')\": True, \"bigram('h', 'a')\": True}, 'en')\n"
     ]
    }
   ],
   "source": [
    "print(featuresets_en[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the feautres in a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feats, test_feats = featuresets_de[200:] + featuresets_en[200:], featuresets_de[:200] + featuresets_en[:200]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With NLTK we can print the accuracy. To calculate the accuray you have to provide the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.8425)\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', nltk.classify.accuracy(classifier, test_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trainned classifier we can now classify a text. The classifier returns if the text is writtine in the German (de) or English (en) language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "print(classifier.classify(get_features_from_sentenece('Mein Name ist Hugo')))\n",
    "print(classifier.classify(get_features_from_sentenece('My name is Hugo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides a method which displayes the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        bigram('e', 'a') = True               en : de     =     26.3 : 1.0\n",
      "        bigram('c', 'e') = True               en : de     =     26.3 : 1.0\n",
      "  trigram('t', 'e', 'n') = True               de : en     =     23.7 : 1.0\n",
      "        bigram('e', 'i') = True               de : en     =     22.3 : 1.0\n",
      "  trigram('e', 'i', 'n') = True               de : en     =     17.7 : 1.0\n",
      "        bigram('t', 'h') = True               en : de     =     17.0 : 1.0\n",
      "        bigram('o', 'w') = True               en : de     =     14.3 : 1.0\n",
      "  trigram('s', 't', 'e') = True               de : en     =     13.0 : 1.0\n",
      "  trigram('s', 'c', 'h') = True               de : en     =     12.2 : 1.0\n",
      "  trigram('c', 'h', 'e') = True               de : en     =     12.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation is key. After you have trained a classifier you should get some basic metrics like precision and recall for every label. NLTK provides methods to calulate the most common metrics to evaluate a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE precision: 0.844221105528\n",
      "DE recall: 0.84\n",
      "DE F-measure: 0.842105263158\n",
      "EN precision: 0.8407960199\n",
      "EN recall: 0.845\n",
      "EN F-measure: 0.84289276808\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import nltk.metrics\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_feats):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print 'DE precision:', nltk.metrics.precision(refsets['de'], testsets['de'])\n",
    "print 'DE recall:', nltk.metrics.recall(refsets['de'], testsets['de'])\n",
    "print 'DE F-measure:', nltk.metrics.f_measure(refsets['de'], testsets['de'])\n",
    "print 'EN precision:', nltk.metrics.precision(refsets['en'], testsets['en'])\n",
    "print 'EN recall:', nltk.metrics.recall(refsets['en'], testsets['en'])\n",
    "print 'EN F-measure:', nltk.metrics.f_measure(refsets['en'], testsets['en'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
