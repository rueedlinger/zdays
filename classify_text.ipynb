{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def get_features(word):\n",
    "    word = word.lower()\n",
    "    \n",
    "    feature = {'word('+ word + ')': True}\n",
    "    feature['sufix1'] =  word[-1:]\n",
    "    \n",
    "    \n",
    "    for ngram in  ngrams(word, 2):\n",
    "        feature['bigram' + str(ngram) + ''] = True\n",
    "    \n",
    "        \n",
    "    for ngram in  ngrams(word, 3):\n",
    "        feature['trigram' + str(ngram) + ''] = True\n",
    "    \n",
    "    \n",
    "    return feature\n",
    "        \n",
    "def get_features_from_file(file):\n",
    "\n",
    "    lines = [line.rstrip() for line in open(file)]\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for word in lines:\n",
    "        \n",
    "        features.append(get_features(word))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_features_from_sentenece(sentence):\n",
    "    features = {}\n",
    "    for word in sentence.split(' '):\n",
    "        features.update(get_features(word))\n",
    "    return features\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresets_de = [(f, 'de') for f in get_features_from_file('data/top1000de.txt')]\n",
    "featuresets_en = [(f, 'en') for f in get_features_from_file('data/top1000en.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(featuresets_de)\n",
    "random.shuffle(featuresets_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('German features', 1000)\n",
      "('English features', 1000)\n"
     ]
    }
   ],
   "source": [
    "print('German features', len(featuresets_de))\n",
    "print('English features', len(featuresets_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({\"trigram('d', 'e', 'r')\": True, \"bigram('r', ' ')\": True, \"trigram('r', ' ', 'w')\": True, \"trigram('e', 'd', 'e')\": True, \"bigram('m', 'e')\": True, \"trigram(' ', 'w', 'i')\": True, \"bigram('m', 'm')\": True, \"trigram('e', 'r', ' ')\": True, \"trigram('m', 'e', 'r')\": True, \"bigram(' ', 'w')\": True, \"bigram('i', 'e')\": True, \"trigram('m', 'm', 'e')\": True, \"trigram('i', 'm', 'm')\": True, 'word(immer wieder)': True, 'sufix1': 'r', \"bigram('e', 'r')\": True, \"bigram('w', 'i')\": True, \"trigram('i', 'e', 'd')\": True, \"trigram('w', 'i', 'e')\": True, \"bigram('i', 'm')\": True, \"bigram('d', 'e')\": True, \"bigram('e', 'd')\": True}, 'de')\n",
      "({'word(be)': True, 'sufix1': 'e', \"bigram('b', 'e')\": True}, 'en')\n"
     ]
    }
   ],
   "source": [
    "print(featuresets_de[0])\n",
    "print(featuresets_en[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feats, test_feats = featuresets_de[200:] + featuresets_en[200:], featuresets_de[:200] + featuresets_en[:200]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.8425)\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', nltk.classify.accuracy(classifier, test_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "print(classifier.classify(get_features_from_sentenece('Mein Name ist Hugo')))\n",
    "print(classifier.classify(get_features_from_sentenece('My name is Hugo')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "  trigram('i', 'c', 'h') = True               de : en     =     28.3 : 1.0\n",
      "        bigram('e', 'a') = True               en : de     =     23.7 : 1.0\n",
      "  trigram('s', 'c', 'h') = True               de : en     =     23.0 : 1.0\n",
      "  trigram('c', 'h', 'e') = True               de : en     =     20.3 : 1.0\n",
      "  trigram('e', 'i', 'n') = True               de : en     =     19.7 : 1.0\n",
      "        bigram('e', 'i') = True               de : en     =     18.8 : 1.0\n",
      "  trigram('e', 'i', 't') = True               de : en     =     18.3 : 1.0\n",
      "        bigram('t', 'h') = True               en : de     =     17.4 : 1.0\n",
      "        bigram('h', 'r') = True               de : en     =     16.3 : 1.0\n",
      "        bigram('e', 'h') = True               de : en     =     15.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE precision: 0.8407960199\n",
      "DE recall: 0.845\n",
      "DE F-measure: 0.84289276808\n",
      "EN precision: 0.844221105528\n",
      "EN recall: 0.84\n",
      "EN F-measure: 0.842105263158\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import nltk.metrics\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_feats):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print 'DE precision:', nltk.metrics.precision(refsets['de'], testsets['de'])\n",
    "print 'DE recall:', nltk.metrics.recall(refsets['de'], testsets['de'])\n",
    "print 'DE F-measure:', nltk.metrics.f_measure(refsets['de'], testsets['de'])\n",
    "print 'EN precision:', nltk.metrics.precision(refsets['en'], testsets['en'])\n",
    "print 'EN recall:', nltk.metrics.recall(refsets['en'], testsets['en'])\n",
    "print 'EN F-measure:', nltk.metrics.f_measure(refsets['en'], testsets['en'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
